name: deploy

on:
   workflow_dispatch:
      inputs:
         db_folder:
            description: Which database?
            type: choice
            options:
               - ontology
               - sources
               - targets

         input_db_names:
            description: 'TBTA/TaBiThA database(s) needed for the migration'
            type: string
            required: true

         tabitha_db_name:
            description: 'Name of the TaBiThA sqlite database'
            type: string
            required: true

jobs:
   init:
      runs-on: ubuntu-latest
      steps:
         -
            uses: actions/checkout@v4
         -
            uses: oven-sh/setup-bun@v2
         -
            id: vars
            run: bun .github/workflows/init.ts ${{ inputs.input_db_names }} ${{ inputs.tabitha_db_name }} >> $GITHUB_OUTPUT
         -
            run: |
               echo "inputs: ${{ toJSON(inputs) }}"
               echo "env: ${{ toJSON(env) }}"
               echo "steps: ${{ toJSON(steps) }}"
               echo "secrets: ${{ toJSON(secrets) }}"

      outputs:
         TABITHA_DB_NAME: ${{ steps.vars.outputs.OUTPUT_DB_NAME }}
         TABITHA_DB_DUMP: ${{ steps.vars.outputs.OUTPUT_DB_DUMP }}
         DEPLOY_DB_NAME: ${{ steps.vars.outputs.DEPLOY_DB_NAME }}

   migrate:
      needs: init
      runs-on: ubuntu-latest

      steps:
         -
            uses: actions/checkout@v4
         -
            uses: oven-sh/setup-bun@v2
         -
            name: migrate TBTA data to TaBiThA
            run: bun ${{ inputs.db_folder }}/migrate.ts ${{ inputs.input_db_names }} ${{ needs.init.outputs.TABITHA_DB_NAME }}
         -
            name: Dump tables
            # grep -v is because of https://developers.cloudflare.com/d1/build-with-d1/import-export-data/#convert-sqlite-database-files
            run: sqlite3 ${{ needs.init.outputs.TABITHA_DB_NAME }} .dump | grep -Ev "^PRAGMA|^BEGIN TRANSACTION|^COMMIT" > ${{ needs.init.outputs.TABITHA_DB_DUMP }}
         -
            name: Created files
            run: ls -ltr ${{ needs.init.outputs.TABITHA_DB_NAME }}*
         -
            name: Store dump
            uses: actions/upload-artifact@v4
            with:
               name: tabitha-dump
               path: ${{ needs.init.outputs.TABITHA_DB_DUMP }}

   deploy:
      needs: [init, migrate]
      runs-on: ubuntu-latest

      steps:
         -
            name: Get dump file
            uses: actions/download-artifact@v4
            with:
               name: tabitha-dump
         -
            name: Reveal dump file
            run: ls -ltr
         -
            name: Get current databases
            id: db_list
            uses: cloudflare/wrangler-action@v3
            with:
               apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
               # https://developers.cloudflare.com/workers/wrangler/commands/#list
               command: d1 list --json
         -
            name: Current databases (simplified)
            run: echo '${{ steps.db_list.outputs.command-output }}' | jq '.[].name' | sort
         -
            name: Create new database
            uses: cloudflare/wrangler-action@v3
            with:
               apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
               # https://developers.cloudflare.com/workers/wrangler/commands/#create
               command: d1 create ${{ needs.init.outputs.DEPLOY_DB_NAME }}
         -
            name: Load data
            uses: cloudflare/wrangler-action@v3
            with:
               apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
               # https://developers.cloudflare.com/workers/wrangler/commands/#execute
               # note: --remote is default in the CI apparently.
               command: d1 execute ${{ needs.init.outputs.DEPLOY_DB_NAME }} --file=${{ needs.init.outputs.TABITHA_DB_DUMP }}
         -
            name: Smoke test
            uses: cloudflare/wrangler-action@v3
            with:
               apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
               # https://developers.cloudflare.com/workers/wrangler/commands/#execute
               # note: --remote is default in the CI apparently.
               command: d1 execute ${{ needs.init.outputs.DEPLOY_DB_NAME }} --command="select name from sqlite_master"
