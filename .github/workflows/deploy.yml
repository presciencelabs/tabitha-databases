name: deploy

on:
   workflow_dispatch:
      inputs:
         db_folder:
            description: Which database?
            type: choice
            options:
               - ontology
               - sources

         tbta_db_name:
            description: 'Name of the TBTA mdb(s) converted to sqlite'
            type: string
            required: true

jobs:
   init:
      runs-on: ubuntu-latest
      steps:
         -
            uses: actions/checkout@v4
         -
            uses: oven-sh/setup-bun@v2
         -
            id: vars
            run: bun .github/workflows/init.js ${{ inputs.db_folder }} ${{ inputs.tbta_db_name }} >> $GITHUB_OUTPUT
         -
            run: |
               echo "inputs: ${{ toJSON(inputs) }}"
               echo "env: ${{ toJSON(env) }}"
               echo "steps: ${{ toJSON(steps.vars.outputs) }}"
               echo "secrets: ${{ toJSON(secrets) }}"

  #  config:
  #     runs-on: ubuntu-latest

  #     steps:
  #        -
  #           run: echo "TABITHA_DB_NAME=$(echo ${{ inputs.tbta_db_name }} | sed 's/mdb/tabitha/')" >> $GITHUB_ENV
  #        -
  #           run: echo "TABITHA_DB_DUMP=${{ env.TABITHA_DB_NAME }}.sql" >> $GITHUB_ENV
  #        -
  #           run: echo "DEPLOY_DB_NAME=$(echo ${{ env.TABITHA_DB_NAME }} | sed 's/.tabitha.sqlite//')" >> $GITHUB_ENV
  #        -
  #           run: |
  #              echo "inputs: ${{ toJSON(inputs) }}"
  #              echo "env: ${{ toJSON(env) }}"
  #              echo "secrets: ${{ toJSON(secrets) }}"

  #     outputs:
  #        TABITHA_DB_NAME: ${{ env.TABITHA_DB_NAME }}
  #        TABITHA_DB_DUMP: ${{ env.TABITHA_DB_DUMP }}
  #        DEPLOY_DB_NAME: ${{ env.DEPLOY_DB_NAME }}

  #  verify:
  #     if: false
  #     runs-on: ubuntu-latest

  #     steps:
  #        -
  #           uses: actions/checkout@v4
  #        -
  #           name: Verify file naming convention (must end with `.mdb.sqlite`)
  #           run: ${{ endsWith(inputs.tbta_db_name, '.mdb.sqlite') }}
  #        -
  #           name: Check for existence of file
  #           run: test -f ./tbta_dbs_as_sqlite/${{ inputs.tbta_db_name }}

  #  migrate:
  #     needs: [config, verify]
  #     runs-on: ubuntu-latest

  #     steps:
  #        -
  #           uses: actions/checkout@v4
  #        -
  #           uses: oven-sh/setup-bun@v2
  #        -
  #           name: migrate Ontology from TBTA to TaBiThA
  #           run: bun ${{ inputs.db_folder }}/migrate.js ./tbta_dbs_as_sqlite/${{ inputs.tbta_db_name }} ${{ inputs.db_folder }}/${{ needs.config.outputs.TABITHA_DB_NAME }}
  #        -
  #           name: Dump tables
  #           # grep -v is because of https://developers.cloudflare.com/d1/build-with-d1/import-export-data/#convert-sqlite-database-files
  #           run: sqlite3 ${{ inputs.db_folder }}/${{ needs.config.outputs.TABITHA_DB_NAME }} .dump | grep -Ev "^PRAGMA|^BEGIN TRANSACTION|^COMMIT" > ${{ inputs.db_folder }}/${{ needs.config.outputs.TABITHA_DB_DUMP }}
  #        -
  #           name: Created files
  #           run: ls -ltr ${{ inputs.db_folder }}/${{ needs.config.outputs.TABITHA_DB_NAME }}*
  #        -
  #           name: Store dump
  #           uses: actions/upload-artifact@v4
  #           with:
  #              name: tabitha-dump
  #              path: ${{ inputs.db_folder }}/${{ needs.config.outputs.TABITHA_DB_DUMP }}

  #  deploy:
  #     needs: [config, migrate]
  #     runs-on: ubuntu-latest

  #     steps:
  #        -
  #           name: Get dump file
  #           uses: actions/download-artifact@v4
  #           with:
  #              name: tabitha-dump
  #        -
  #           name: Reveal dump file
  #           run: ls -ltr
  #        -
  #           name: Get current databases
  #           id: db_list
  #           uses: cloudflare/wrangler-action@v3
  #           with:
  #              apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
  #              # https://developers.cloudflare.com/workers/wrangler/commands/#list
  #              command: d1 list --json
  #        -
  #           name: Current databases (simplified)
  #           run: echo '${{ steps.db_list.outputs.command-output }}' | jq '.[].name' | sort
  #        -
  #           name: Create new database
  #           uses: cloudflare/wrangler-action@v3
  #           with:
  #              apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
  #              # https://developers.cloudflare.com/workers/wrangler/commands/#create
  #              command: d1 create ${{ needs.config.outputs.DEPLOY_DB_NAME }}
  #        -
  #           name: Load data
  #           uses: cloudflare/wrangler-action@v3
  #           with:
  #              apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
  #              # https://developers.cloudflare.com/workers/wrangler/commands/#execute
  #              # note: --remote is default in the CI apparently.
  #              command: d1 execute ${{ needs.config.outputs.DEPLOY_DB_NAME }} --file=./${{ needs.config.outputs.TABITHA_DB_DUMP }}
  #        -
  #           name: Smoke test
  #           uses: cloudflare/wrangler-action@v3
  #           with:
  #              apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
  #              # https://developers.cloudflare.com/workers/wrangler/commands/#execute
  #              # note: --remote is default in the CI apparently.
  #              command: d1 execute ${{ needs.config.outputs.DEPLOY_DB_NAME }} --command="select name from sqlite_master"
